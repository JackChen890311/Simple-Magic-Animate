# Simple-Magic-Animate

This repository demostrates a simple pipeline of magic-animate usage, including human pose estimation using densepose. (which is the annoying part)  

## Original Github Repository Link
 - [Magic-Animate](https://github.com/magic-research/magic-animate) (Using Commit Version ae5faa8)
 - [Densepose from Detectron2](https://github.com/facebookresearch/detectron2/tree/main/projects/DensePose)

## Environment Setup
I recommend using two different environments as there might be a version conflict. Please refer to their github repositories for environment setup.  
Please also note that using densepose require detectron2 installed. See [here](https://detectron2.readthedocs.io/en/latest/tutorials/install.html) for more details.

## How to use it?
![](magic.gif)

To run magic-animate, we'll need:
 - A reference image
 - A motion sequence (Generated by densepose)

Resolution is set at 512 x 512 for better result, you can also try different resolutions.  

**Change the paths and numbers if needed.**  

For image, you can crop it by yourself, or use `magic-animate/crop_image.py` to crop image with Opencv.  

For motion sequence, use `DensePose/apply_video.py` to generate motion sequence, and use `magic-animate/pad_video.py` to pad it into 512 x 512.  

Finally, use `magic-animate/inference.py` to run magic-animate inference. You should find your result at `magic-animate/demo/outputs`.

Feel free to reach out if there's anything unclear, I'll try my best to help. If you find this repository useful, please consider leave a star ‚≠ê 

Thanks :)



